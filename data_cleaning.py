# -*- coding: utf-8 -*-
"""data cleaning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sfcUP3Zi8Vxoh52CG6tDS5wgy4h6ZaxZ
"""

import csv

with open('sen.csv', 'r') as input_file, open('output_file.csv', 'w', newline='') as output_file:
    reader = csv.reader(input_file)
    writer = csv.writer(output_file)
    for row in reader:
        if row[6]:
            writer.writerow(row)

import csv

def find_same_rows(data, column_index):
    same_rows = []
    current_value = None
    current_row_indices = []

    for i, row in enumerate(data):
        if current_value is None or row[column_index] != current_value:
            if current_row_indices and len(current_row_indices) > 1:
                same_rows.append(current_row_indices)
            current_value = row[column_index]
            current_row_indices = [i]
        else:
            current_row_indices.append(i)

    if current_row_indices and len(current_row_indices) > 1:
        same_rows.append(current_row_indices)

    return same_rows

def get_values_by_indices(data, indices, column_index):
    return [row[column_index] for i, row in enumerate(data) if i in indices]

with open("output_file.csv", "r") as file:
    reader = csv.reader(file)
    data = [row for row in reader]

same_rows = find_same_rows(data, 6)
same_values = [get_values_by_indices(data, indices, 13) for indices in same_rows]

#for values in same_values:
    #print(values)

import pandas as pd

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('ID_updated.csv')
id_map = {}
for id_list in same_values:
    new_id = id_list[0]
    for old_id in id_list:
        id_map[old_id] = new_id
print(id_map)
df['ID_REF'] = df['ID_REF'].replace(id_map)
df[df.duplicated(['ID_REF'])]
grouped_df = df.groupby('ID_REF').mean()
grouped_df = grouped_df.reset_index()
np.where(np.asanyarray(pd.isna(grouped_df)))
grouped_df.to_csv('ID_grouped.csv', index=False)

import pandas as pd
df = pd.read_csv('ID_grouped.csv')
df_transposed = df.T
print(np.where(np.asanyarray(pd.isna(df))))
df_transposed.to_csv('ID_transposed.csv', header=False)

"""merging input and label"""

import pandas as pd
lf = pd.read_csv('label_class.csv')
label_map = {}
for i in range(lf['ID_REF'].size):
  label_map[lf['ID_REF'][i]] = lf['class'][i]
df = pd.read_csv('ID_transposed.csv')
classes = []
for i in range(df['ID_REF'].size):
  if df['ID_REF'][i] in label_map:
    classes.append(label_map[df['ID_REF'][i]])
  else:
    classes.append("")
df['class'] = classes
print(np.where(np.asanyarray(pd.isna(df))))
df.to_csv('classes_merged.csv', index=False)

"""**T Test**"""

import pandas as pd

# Read the CSV file
df = pd.read_csv('classes_merged.csv')
X = df.drop(['ID_REF','class'] ,axis=1)
#X =X.dropna(axis=1,inplace=True)
y=df['class']

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
import numpy as np
scaler = StandardScaler()
X_scale= scaler.fit_transform(X)
label_encoder = LabelEncoder()
label_encoder.fit(y)
y = label_encoder.transform(y)
np.where(np.asanyarray(np.isnan(X)))

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.20,shuffle=True,random_state=10)

from sklearn.feature_selection import f_classif
f_scores, p_values = f_classif(X, y)
feature_scores = {}
for i in range(len(X.columns)):
    feature_scores[X.columns[i]] = (f_scores[i], p_values[i])
sorted_features = sorted(feature_scores.items(), key=lambda x: x[1][0], reverse=True)
for feature, (f_score, p_value) in sorted_features:
    print(f'{feature}: f-score={f_score:.2f}, p-value={p_value:.2f}')

from sklearn.feature_selection import f_classif
f_scores, p_values = f_classif(X, y)
top_features = []
k=10000
for i in range(k):
    top_features.append(X.columns[f_scores.argmax()])
    f_scores[f_scores.argmax()] = 0  # Set the maximum f-score to 0 to avoid selecting the same feature twice
print(top_features)

df_selected = df.drop(columns=[col for col in df.columns if col not in top_features])
X_selected = df.drop(['ID_REF','class'] ,axis=1)
y_selected=df['class']
label_encoder = LabelEncoder()
label_encoder.fit(y_selected)
y_selected = label_encoder.transform(y_selected)

"""K-means"""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=2, random_state=0)
kmeans.fit(X_selected)

predicted_labels = kmeans.predict(X_selected)

from sklearn.metrics import accuracy_score
acc = accuracy_score(y_selected, predicted_labels)
print("Accuracy:", acc)

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
df = pd.read_csv('classes_merged.csv')
X = df.drop(['ID_REF','class'] ,axis=1)
y=df['class']
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scale= scaler.fit_transform(X)
label_encoder = LabelEncoder()
label_encoder.fit(y)
y = label_encoder.transform(y)
X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.10,random_state=10)
kmeans = KMeans(n_clusters=2, random_state=42)
kmeans.fit(X_train)
y_train_pred = kmeans.predict(X_train)
y_test_pred = kmeans.predict(X_test)
acc_train = accuracy_score(y_train, y_train_pred)
acc_test = accuracy_score(y_test, y_test_pred)
print("Train acc score:", acc_train)
print("Test acc score:", acc_test)