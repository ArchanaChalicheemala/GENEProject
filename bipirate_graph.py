# -*- coding: utf-8 -*-
"""Bipirate graph.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pBN_M2X_99ctuImVIwS8Ak9XVeCDzA7i
"""

!pip install torch_geometric
import pandas as pd
from google.colab import drive
drive.mount('/content/gdrive')
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch_geometric.nn import GCNConv
from torch_geometric.nn import SAGEConv
from torch_geometric.nn import GATConv
from torch_geometric.nn import GINConv

"""# ***DEFINED FUNCTIONS***"""

# TO CHECK IF THERE ARE HAVING ANY MISSING VALUES
def na(df):
  return print(np.where(np.asanyarray(pd.isna(df))))

# MERGING INPUT AND LABEL
def mergeIO(df):
  lf = pd.read_csv('/content/gdrive/My Drive/Masters/project/label.csv')
  label_map = {}
  for i in range(lf['ID_REF'].size):
    label_map[lf['ID_REF'][i]] = lf['class'][i]
  classes = []
  for i in range(df['ID_REF'].size):
    if df['ID_REF'][i] in label_map:
      classes.append(label_map[df['ID_REF'][i]])
    else:
      classes.append("")
  df['class'] = classes
  #na(df)
  df = df.drop(index=df[df['class'].isin(['POST', 'PRE'])].index).reset_index(drop=True)
  return df

# TO SAVE THE DATAFRAME INTO X AND Y .NPY FILES
def npy(df):
  X = df.drop(['ID_REF','class'] ,axis=1)
  y=df['class']
  X.to_numpy()
  y.to_numpy
  return X,y

def matrix_sparsity(matrix):
    total_elements = matrix.shape[0] * matrix.shape[1]
    non_zero_elements = (matrix != 0).sum()
    print('Number of non_zero elements',non_zero_elements)
    zero_elements = total_elements - non_zero_elements
    sparsity = (zero_elements / total_elements) * 100
    return sparsity

def admatrix(G):
  # get adjacency matrix
  adj_matrix = nx.to_numpy_array(G)
  np.fill_diagonal(adj_matrix, 1)
  # print adjacency matrix
  print(adj_matrix)
  print('Dimension of adjacency matrix is', adj_matrix.shape)
  return adj_matrix

"""# ***PROBE_IDS GRAPH FROM BIOGRID DATA [G1]***"""

# Read in the data
sen = pd.read_csv('/content/gdrive/My Drive/Masters/project/sen.csv', low_memory=False)
df = pd.read_csv('/content/gdrive/My Drive/Masters/project/Book3.csv')
label= pd.read_csv('/content/gdrive/My Drive/Masters/project/label.csv')
l = sen[['Entrez_Gene_ID','Probe_Id']].dropna()

#Map entrez gene ID to Probe_ID
map_dict = l.set_index('Entrez_Gene_ID')['Probe_Id'].to_dict()
print('Number of probe_ID with entrez gene ID',len(map_dict))

# Filter the interactions to include only genes with Entrez IDs in sen.csv
entrez_ids = list(l['Entrez_Gene_ID'])
print(len(entrez_ids))
df = df[df['Entrez Gene Interactor A'].isin(entrez_ids) & df['Entrez Gene Interactor B'].isin(entrez_ids)]

# create empty graph
G= nx.Graph()

# add edges with weights
count=0
for i, row in df.iterrows():
    a = map_dict.get(row['Entrez Gene Interactor A'], None)
    b = map_dict.get(row['Entrez Gene Interactor B'], None)
    if a is not None and b is not None:
        G.add_edge(a, b, weight=1)
        #G.add_edge(b,a,weight=1)
        count+=1
print("Number of probe_ID pairs connected ",count)

# Convert the graph to undirected
G = G.to_undirected()

# create an empty graph
G1 = nx.Graph()

# Get the list of probe_ids that are present in the adjacency matrix
data = pd.read_csv('/content/gdrive/My Drive/Masters/project/data.csv')
probe_ids = list(data["ID_REF"])
print(len(probe_ids))
probe_ids_adj=G.nodes()
print(len(probe_ids_adj))
present_probe_ids = []
for probe_id in probe_ids_adj:
    if probe_id in probe_ids:
        present_probe_ids.append(probe_id)
print(len(set(present_probe_ids)))


# find the intersection of the two sets
common_probe_ids = list(set(probe_ids).intersection(set(probe_ids_adj)))

# add the common Probe IDs as nodes in G1
G1.add_nodes_from(common_probe_ids)

# add the edges from G that connect the common Probe IDs
for edge in G.edges():
    if edge[0] in common_probe_ids and edge[1] in common_probe_ids:
        G1.add_edge(edge[0], edge[1], weight=G.get_edge_data(edge[0], edge[1])['weight'])

# Find the number of nodes
num_nodes = G1.number_of_nodes()
print("Number of nodes in graph ", num_nodes) 

# get adjacency matrix
adj_matrix = nx.to_numpy_array(G1)
np.fill_diagonal(adj_matrix, 1)

# print adjacency matrix
print(adj_matrix)
print('Dimension of adjacency matrix is', adj_matrix.shape)

if np.array_equal(adj_matrix, adj_matrix.T):
    print("Matrix is symmetric, graph is undirected")

q=matrix_sparsity(adj_matrix)
print("The sparsity of adjacency matrix is:", q, "%")


# print nodes and edges
probe_ids=G1.nodes()
print("Nodes: ", G1.nodes())
print( "Number of nodes", len(G1.nodes()))
print("Edges: ", G1.edges())
print("Number of edges", len(G1.edges()))


#TO VIEW THE GRAPH
import matplotlib.pyplot as plt

# Draw the graph
pos = nx.spring_layout(G1)
nx.draw(G1, pos)

# Draw labels for nodes
labels = {n: n for n in G1.nodes()}
nx.draw_networkx_labels(G1, pos, labels, font_size=10)

# Show the plot
plt.show()


#GRAPH FOR LESS NUMBER OF NODES
# Convert the graph to undirected
G_undirected = G1.to_undirected()

# Get a list of connected components
components = list(nx.connected_components(G_undirected))

# Select a component with 20-30 nodes
selected_component = None
for component in components:
    if len(component) >= 20 and len(component) <= 30:
        selected_component = component
        break

# Create a subgraph with selected nodes
subgraph = G1.subgraph(selected_component)

# Draw the subgraph
pos = nx.spring_layout(subgraph, k=0.5)
nx.draw(subgraph, pos, with_labels=True)
plt.show()
matrix_sparsity(admatrix(G1))

"""# ***PROBE_IDS AND PATIENT_IDS GRAPH FROM GENE DATA [G2]***"""

import pandas as pd
import networkx as nx

data = pd.read_csv('/content/gdrive/My Drive/Masters/project/data.csv')
data = data.T
data.to_csv('data.csv', header=False)
data= pd.read_csv('data.csv')
data=mergeIO(data)
data.set_index("ID_REF", inplace=True)

from sklearn.preprocessing import MinMaxScaler
# get the columns to normalize
cols_to_normalize = data.columns[:-1] # excluding the 'class' column
# create a scaler object
scaler = MinMaxScaler()
# normalize the columns and overwrite the original data
data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])

# find the intersection of the two sets
common_probe_ids = list(set(probe_ids).intersection(set(probe_ids_adj)))

# create a list of unique patient ids
patient_ids = list(data.index)

# initialize empty graph object
G2 = nx.Graph()

count1=0
# add probe ids as nodes
for probe_id in common_probe_ids:
    G2.add_node(probe_id, node_type='probe')
    count1+=1
print(count1)
count2=0
# add patient ids as nodes
for patient_id in patient_ids:
    G2.add_node(patient_id, node_type='patient')
    count2+=1
print(count2)
count3=0
# add edges between probe and patient ids
for index, row in data.iterrows():
    patient_id = index
    for probe_id, expression_value in row.items():
      if probe_id in common_probe_ids:
            G2.add_edge(probe_id, patient_id, weight=expression_value)
            count3 += 1
print(count3)
#GRAPH FOR LESS NUMBER OF NODES


import networkx as nx
import matplotlib.pyplot as plt

# create a subgraph with selected nodes and edges
selected_nodes = ['GSM334518', 'ILMN_1738632', 'ILMN_1674390','ILMN_1750364','GSM334511','ILMN_1750364', 'ILMN_1766085']
selected_edges = [('ILMN_1674390', 'GSM334518'), ('ILMN_1738632', 'ILMN_1674390'),('ILMN_1750364', 'ILMN_1766085')]
subgraph = G2.subgraph(selected_nodes).copy()
subgraph.add_edges_from(selected_edges)

# draw the subgraph
pos = nx.spring_layout(subgraph, k=0.5)
nx.draw(subgraph, pos, with_labels=True)
plt.show()
matrix_sparsity(admatrix(G2))

"""# ***MERGING GRAPH1 AND GRAPH2***"""

# Merge the two graphs
G_merged = nx.compose(G2, G1)
count4=0
# Add edges between probe and patient ids
for patient_id in patient_ids:
    for probe_id in probe_ids:
        if G_merged.has_node(patient_id) and G_merged.has_node(probe_id):
            count4+=1
            G_merged.add_edge(patient_id, probe_id)
            
print(count4)
# # Draw the merged graph
# pos = nx.spring_layout(G_merged, k=0.5)
# nx.draw(G_merged, pos, with_labels=True)
# plt.show()

#GRAPH FOR LESS NUMBER OF NODES
# Convert the graph to undirected
G_undirected = G_merged.to_undirected()

# Get a list of connected components
components = list(nx.connected_components(G_undirected))

# Select a component with 20-30 nodes
selected_component = None
for component in components:
    if len(component) >= 1 and len(component) <= 3:
        selected_component = component
        break

# Create a subgraph with selected nodes
subgraph = G_merged.subgraph(selected_component)

# Draw the subgraph
pos = nx.spring_layout(subgraph, k=0.5)
nx.draw(subgraph, pos, with_labels=True)
plt.show()
matrix_sparsity(admatrix(G_merged))

import networkx as nx
import matplotlib.pyplot as plt

# create a subgraph with selected nodes and edges
selected_nodes = ['GSM334518', 'ILMN_1738632', 'ILMN_1674390','ILMN_1750364','GSM334511','ILMN_1750364', 'ILMN_1766085']
selected_edges = [('ILMN_1674390', 'GSM334518'), ('ILMN_1738632', 'ILMN_1674390'),('ILMN_1750364', 'ILMN_1766085')]
subgraph = G_merged.subgraph(selected_nodes).copy()
subgraph.add_edges_from(selected_edges)

# draw the subgraph with node and edge labels
pos = nx.spring_layout(subgraph, k=0.5)
nx.draw_networkx_nodes(subgraph, pos, nodelist=subgraph.nodes())
nx.draw_networkx_edges(subgraph, pos, edgelist=subgraph.edges())
nx.draw_networkx_labels(subgraph, pos, font_size=10, font_family='sans-serif')
edge_labels = {(edge[0], edge[1]): round(subgraph[edge[0]][edge[1]]['weight'], 2)  for edge in subgraph.edges()}
nx.draw_networkx_edge_labels(subgraph, pos, edge_labels=edge_labels, font_size=10, font_family='sans-serif', label_pos=0.5)
plt.show()

adj_matrix=admatrix(G_merged)
x=a_nodes=G_merged.nodes()

"""# ***FEATURE MATRIX***"""

import pandas as pd
import numpy as np
from sklearn.neural_network import MLPRegressor

# Load the data into a pandas DataFrame
df = pd.read_csv('data.csv', index_col=0)

# Get the patient IDs and probe IDs
patient_ids = [node for node in G_merged.nodes() if node.startswith('GSM')]
probe_ids = [node for node in G_merged.nodes() if node.startswith('ILMN')]

# Create a dictionary to store the feature vectors
feature_dict = {}

# Fill in the feature vectors for the patient nodes
for patient_id in patient_ids:
    features = df.loc[patient_id, common_probe_ids].values
    feature_dict[patient_id] = features

# Fill in the feature vectors for the probe nodes
for probe_id in probe_ids:
    feature_dict[probe_id] = np.zeros(len(probe_ids))
    feature_dict[probe_id][probe_ids.index(probe_id)] = 1

# Convert the dictionary to a numpy array
feature_matrix = np.zeros((len(patient_ids) + len(probe_ids), len(probe_ids)))
for i, node_id in enumerate(G_merged.nodes()):
    if node_id in feature_dict:
        feature_matrix[i, :] = feature_dict[node_id]

# Transpose the feature matrix and append zeros for each patient node
feature_matrix = np.vstack((feature_matrix.T, np.zeros((len(patient_ids), feature_matrix.shape[0])))).T
print(feature_matrix.shape)
print(feature_matrix)

"""# ***LABELS***"""

df = pd.read_csv('data.csv')
df=mergeIO(df)
labels = df.loc[:, 'class']
label_to_number = {'NSCLC': 0, 'NHC': 1}
labels = labels.map(label_to_number)
labels = torch.tensor(labels.to_numpy(), dtype=torch.long)
labels = labels.unsqueeze(1) 
# labels = F.one_hot(labels, num_classes=2).to(torch.float32)
print(labels.shape)

"""# ***GCN***"""

from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
# Define the GCN model with configurable hidden layers and number of layers
class GCN(torch.nn.Module):
    def __init__(self, hidden_layers=16, num_layers=1):
        super(GCN, self).__init__()
        self.conv_layers = torch.nn.ModuleList([GCNConv(1077, hidden_layers)])
        for i in range(num_layers - 1):
            self.conv_layers.append(GCNConv(hidden_layers, hidden_layers))
        self.mlp = torch.nn.Linear(hidden_layers, 1)

    def forward(self, x, edge_index):
        for conv in self.conv_layers:
            x = conv(x, edge_index)
            x = x.relu()
        x = self.mlp(x)
        return x

# Convert data to PyTorch format
features_t = torch.tensor(feature_matrix, dtype=torch.float)
adj_t = torch.tensor(adj_matrix, dtype=torch.float)
labels_t = labels.clone().detach().to(torch.float)
edge_index = adj_t.nonzero().t().contiguous().clone().detach().to(torch.long)

# Define the loss function
criterion = torch.nn.BCEWithLogitsLoss()

# Perform k-fold cross validation for different hidden layers and number of layers
k = 10
kf = KFold(n_splits=k, shuffle=True)
Title = []
ACC_TR = []
ACC_TS = []
PREC = []
REC = []
F_SCORE = []
for hidden_layer in [8, 16, 64, 128, 256]:
    for num_layer in [1, 2, 3]:
        print(f"Training GCN with {num_layer} layers and {hidden_layer} hidden units")
        total_acc = 0
        for i, (train_index, test_index) in enumerate(kf.split(labels_t)):
            # Create train and test masks
            train_mask = torch.zeros(len(labels_t), dtype=torch.bool)
            train_mask[train_index] = True
            test_mask = torch.zeros(len(labels_t), dtype=torch.bool)
            test_mask[test_index] = True
            x=len(train_index)
            patient_indices_train=list(range(822,822+x))
            patient_indices_test=list(range(822+x,1077))

            # Initialize model and optimizer
            model = GCN(hidden_layers=hidden_layer, num_layers=num_layer)
            optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

            # Train the model
            for epoch in range(30):
                model.train()
                optimizer.zero_grad()
                out = model(features_t, edge_index)
                patient_nodes = torch.tensor(patient_indices_train, dtype=torch.long)
                train_loss = criterion(out[patient_nodes], labels_t[train_mask])
                train_loss.backward()
                optimizer.step()

            # Evaluate on the test set
            model.eval()
            out = model(features_t, edge_index)
            patient_nodes = torch.tensor(patient_indices_test, dtype=torch.long)
            test_loss = criterion(out[patient_nodes], labels_t[test_mask])
            pred = (out[patient_nodes] > 0.5).int()
            # correct = (pred == labels_t[test_mask]).sum().item()
            # total = test_mask.sum().item()
            # acc = correct / max(1, total)
            acc=accuracy_score(pred,labels_t[test_mask] )
            total_acc += acc
        avg_acc = total_acc / k
        Title.append(f"GCN with {num_layer} layers and {hidden_layer} hidden units")
        ACC_TS.append(avg_acc)
        print(f"Accuracy: {avg_acc * 100:.2f}%")

print('GCN')

from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
# Define the GAT model with configurable hidden layers and number of layers
class GAT(torch.nn.Module):
    def __init__(self, hidden_layers=16, num_layers=1):
        super(GAT, self).__init__()
        self.conv_layers = torch.nn.ModuleList([GATConv(1077, hidden_layers)])
        for i in range(num_layers - 1):
            self.conv_layers.append(GATConv(hidden_layers, hidden_layers))
        self.mlp = torch.nn.Linear(hidden_layers, 1)

    def forward(self, x, edge_index):
        for conv in self.conv_layers:
            x = conv(x, edge_index)
            x = x.relu()
        x = self.mlp(x)
        return x

# Convert data to PyTorch format
features_t = torch.tensor(feature_matrix, dtype=torch.float)
adj_t = torch.tensor(adj_matrix, dtype=torch.float)
labels_t = labels.clone().detach().to(torch.float)
edge_index = adj_t.nonzero().t().contiguous().clone().detach().to(torch.long)

# Define the loss function
criterion = torch.nn.BCEWithLogitsLoss()

# Perform k-fold cross validation for different hidden layers and number of layers
k = 10
kf = KFold(n_splits=k, shuffle=True)
Title = []
ACC_TR = []
ACC_TS = []
PREC = []
REC = []
F_SCORE = []
for hidden_layer in [8]:
    for num_layer in [1, 2, 3]:
        print(f"Training GAT with {num_layer} layers and {hidden_layer} hidden units")
        total_acc = 0
        for i, (train_index, test_index) in enumerate(kf.split(labels_t)):
            # Create train and test masks
            train_mask = torch.zeros(len(labels_t), dtype=torch.bool)
            train_mask[train_index] = True
            test_mask = torch.zeros(len(labels_t), dtype=torch.bool)
            test_mask[test_index] = True
            x=len(train_index)
            patient_indices_train=list(range(822,822+x))
            patient_indices_test=list(range(822+x,1077))

            # Initialize model and optimizer
            model = GAT(hidden_layers=hidden_layer, num_layers=num_layer)
            optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

            # Train the model
            for epoch in range(100):
                model.train()
                optimizer.zero_grad()
                out = model(features_t, edge_index)
                patient_nodes = torch.tensor(patient_indices_train, dtype=torch.long)
                train_loss = criterion(out[patient_nodes], labels_t[train_mask])
                train_loss.backward()
                optimizer.step()

            # Evaluate on the test set
            model.eval()
            out = model(features_t, edge_index)
            patient_nodes = torch.tensor(patient_indices_test, dtype=torch.long)
            test_loss = criterion(out[patient_nodes], labels_t[test_mask])
            pred = (out[patient_nodes] > 0.5).int()
            # correct = (pred == labels_t[test_mask]).sum().item()
            # total = test_mask.sum().item()
            # acc = correct / max(1, total)
            acc=accuracy_score(pred,labels_t[test_mask] )
            total_acc += acc
        avg_acc = total_acc / k
        Title.append(f"GAT with {num_layer} layers and {hidden_layer} hidden units")
        ACC_TS.append(avg_acc)
        print(f"Accuracy: {avg_acc * 100:.2f}%")

from sklearn.model_selection import KFold

# Define the GCN model
class GCN(torch.nn.Module):
    def __init__(self):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(1077, 16)
        self.conv2 = GCNConv(16, 16)
        self.mlp = torch.nn.Linear(16, 2)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = self.conv2(x, edge_index)
        x = x.relu()
        x = self.mlp(x)
        return x

# Convert data to PyTorch format
features_t = torch.tensor(feature_matrix, dtype=torch.float)
adj_t = torch.tensor(adj_matrix, dtype=torch.float)
labels_t = labels.clone().detach().to(torch.float)
edge_index = adj_t.nonzero().t().contiguous().clone().detach().to(torch.long)

# Initialize model and optimizer
model = GCN()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Define the loss function
criterion = torch.nn.BCEWithLogitsLoss()

# patient_indices_train=list(range(822,1051))
# patient_indices_test=list(range(1051,1077))


# Perform k-fold cross validation
k = 10
kf = KFold(n_splits=k, shuffle=True)
total_acc = 0
for i, (train_index, test_index) in enumerate(kf.split(labels_t)):
    print("Fold {}/{}".format(i+1, k))
    x=len(train_index)
    patient_indices_train=list(range(822,822+x))
    patient_indices_test=list(range(822+x,1077))
    # Create train and test masks
    train_mask = torch.zeros(len(labels_t), dtype=torch.bool)
    train_mask[train_index] = True
    test_mask = torch.zeros(len(labels_t), dtype=torch.bool)
    test_mask[test_index] = True
    # Train the model
    for epoch in range(30):
        model.train()
        optimizer.zero_grad()
        out = model(features_t, edge_index)
        patient_nodes = torch.tensor(patient_indices_train, dtype=torch.long)
        train_loss = criterion(out[patient_nodes], labels_t[train_mask])
        train_loss.backward()
        optimizer.step()
    # Evaluate on the test set
    model.eval()
    out = model(features_t, edge_index)
    patient_nodes = torch.tensor(patient_indices_test, dtype=torch.long)
    test_loss = criterion(out[patient_nodes], labels_t[test_mask])
    #pred = (out[patient_nodes] > 0.5).float()
    pred = torch.argmax(out[patient_nodes], dim=1)
    correct = (pred == labels_t[test_mask]).sum().item()
    total = test_mask.sum().item()
    acc = correct / total
    total_acc += acc
    print("Accuracy: {:.2f}%".format(acc * 100))

avg_acc = total_acc / k
print("Average accuracy: {:.2f}%".format(avg_acc * 100))

# Define the GCN model
class GCN(torch.nn.Module):
    def __init__(self, hidden_layer_sizes, num_layers):
        super(GCN, self).__init__()
        self.num_layers = num_layers
        self.hidden_layer_sizes = hidden_layer_sizes
        
        self.conv_layers = torch.nn.ModuleList()
        self.conv_layers.append(GCNConv(1077, hidden_layer_sizes))
        for i in range(num_layers - 1):
            self.conv_layers.append(GCNConv(hidden_layer_sizes, hidden_layer_sizes))
            
        self.mlp = torch.nn.Linear(hidden_layer_sizes, 2)

    def forward(self, x, edge_index):
        for i in range(self.num_layers):
            x = self.conv_layers[i](x, edge_index)
            x = x.relu()
        x = self.mlp(x)
        return x


# Convert data to PyTorch format
features_t = torch.tensor(feature_matrix, dtype=torch.float)
adj_t = torch.tensor(adj_matrix, dtype=torch.float)
labels_t = labels.clone().detach().to(torch.float)
edge_index = adj_t.nonzero().t().contiguous().clone().detach().to(torch.long)

kf = KFold(n_splits=5, shuffle=True)
Title = []
ACC_TR = []
ACC_TS = []
PREC = []
REC = []
F_SCORE = []

for hidden_layer in [8,16,64,128]:
    for num_layer in [1,2,3]:
        print("Training GCN with {} hidden layers and {} layers".format(hidden_layer, num_layer))
        f = []
        p = []
        r = []
        acc_test = []
        acc_train = []
        for i, (train_index, test_index) in enumerate(kf.split(labels_t)):
            print(len(train_index))
            print("Fold {}/{}".format(i+1, kf.get_n_splits()))
            x=len(train_index)
            patient_indices_train=list(range(822,822+x))
            patient_indices_test=list(range(822+x,1077))
            X_train = features_t[patient_indices_train]
            y_train = labels_t[train_index]
            X_test = features_t[patient_indices_test]
            y_test = labels_t[test_index]

            # Initialize model and optimizer
            model = GCN(hidden_layer, num_layer)
            optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

            # Define the loss function
            criterion = torch.nn.BCEWithLogitsLoss()

            # Train the model
            for epoch in range(30):
                model.train()
                optimizer.zero_grad()
                out = model(X_train, edge_index)
                patient_nodes = torch.tensor(patient_indices_train, dtype=torch.long)
                train_loss = criterion(out[patient_nodes], y_train)
                train_loss.backward()
                optimizer.step()

            # Evaluate on the test set
            model.eval()
            out = model(X_test, edge_index)
            patient_nodes = torch.tensor(patient_indices_test, dtype=torch.long)
            test_loss = criterion(out[patient_nodes], y_test)
            pred = (out[patient_nodes] > 0.5).float()
            correct = (pred == y_test).sum().item()
            total = test_mask.sum().item()
            acc = correct / total
            acc_test.append(acc)
            acc_train.append(train_loss.item())
            pfs = precision_recall_fscore_support(y_test[test_mask], pred, average='weighted')
            f.append(pfs[2])
            p.append(pfs[0])
            r.append(pfs[1])

        Title.append('GCN ' + ' hidden layer:'+ str(hidden_layer) +' num_layer:' + str(num_layer))
        ACC_TR.append(np.mean(acc_train))
        ACC_TS.append(np.mean(acc_test))

# Define the GCN model
class GCN(torch.nn.Module):
    def __init__(self):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(1077, 16)
        self.conv2 = GCNConv(16, 16)
        self.mlp = torch.nn.Linear(16, 2)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = self.conv2(x, edge_index)
        x = x.relu()
        x = self.mlp(x)
        return x

# Convert data to PyTorch format
features_t = torch.tensor(feature_matrix, dtype=torch.float)
adj_t = torch.tensor(adj_matrix, dtype=torch.float)
labels_t = labels.clone().detach().to(torch.float)
edge_index = adj_t.nonzero().t().contiguous().clone().detach().to(torch.long)

# Split the data into training and testing sets
train_mask = torch.zeros(len(labels_t), dtype=torch.bool)
train_mask[:200] = True
test_mask = torch.zeros(len(labels_t), dtype=torch.bool)
test_mask[200:] = True

patient_indices_train=list(range(822,1022))
patient_indices_test=list(range(1022,1077))

# Initialize model and optimizer
model = GCN()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Define the loss function
criterion = torch.nn.BCEWithLogitsLoss()

# Train the model
for epoch in range(30):
    model.train()
    optimizer.zero_grad()
    out = model(features_t, edge_index)
    patient_nodes = torch.tensor(patient_indices_train, dtype=torch.long)
    train_loss = criterion(out[patient_nodes], labels_t[train_mask])
    train_loss.backward()
    optimizer.step()

# Evaluate on the entire dataset
model.eval()
out = model(features_t, edge_index)
patient_nodes = torch.tensor(patient_indices_test, dtype=torch.long)
test_loss = criterion(out[patient_nodes], labels_t[test_mask])
pred = (out[patient_nodes]> 0.5).float()
correct = (pred==labels_t[test_mask]).sum().item()
total = test_mask.sum().item()
acc = correct / total
print("Accuracy: {:.2f}%".format(acc * 100))

# Define the GCN model
class GCN(torch.nn.Module):
    def __init__(self):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(1077, 16)
        self.conv2 = GCNConv(16, 16)
        self.mlp = torch.nn.Linear(16, 2)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = self.conv2(x, edge_index)
        x = x.relu()
        x = self.mlp(x)
        return x

# Convert data to PyTorch format
features_t = torch.tensor(feature_matrix, dtype=torch.float)
adj_t = torch.tensor(adj_matrix, dtype=torch.float)
labels_t = labels.clone().detach().to(torch.float)
edge_index = adj_t.nonzero().t().contiguous().clone().detach().to(torch.long)

# Split the data into training and testing sets
train_mask = torch.zeros(len(labels_t), dtype=torch.bool)
train_mask[:230] = True
test_mask = torch.zeros(len(labels_t), dtype=torch.bool)
test_mask[230:] = True

patient_indices_train=list(range(1,231))
patient_indices_test=list(range(231,256))

# Initialize model and optimizer
model = GCN()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Define the loss function
criterion = torch.nn.BCEWithLogitsLoss()

# Train the model
for epoch in range(30):
    model.train()
    optimizer.zero_grad()
    out = model(features_t, edge_index)
    patient_nodes = torch.tensor(patient_indices_train, dtype=torch.long)
    train_loss = criterion(out[patient_nodes], labels_t[train_mask])
    train_loss.backward()
    optimizer.step()

# Evaluate on the test set
model.eval()
out = model(features_t, edge_index)
patient_nodes = torch.tensor(patient_indices_test, dtype=torch.long)
test_loss = criterion(out[patient_nodes], labels_t[test_mask])
pred = (out[patient_nodes]> 0.5).float()
correct = (pred==labels_t[test_mask]).sum().item()
acc = correct / test_mask.sum().item()
print("Test accuracy: {:.2f}%".format(acc * 100))

# Define the GCN model
class GCN(torch.nn.Module):
    def __init__(self):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(1077, 16)
        self.conv2 = GCNConv(16, 16)
        self.mlp = torch.nn.Linear(16, 2)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = self.conv2(x, edge_index)
        x = x.relu()
        x = self.mlp(x)
        return x

# Convert data to PyTorch format
features_t = torch.tensor(feature_matrix, dtype=torch.float)
adj_t = torch.tensor(adj_matrix, dtype=torch.float)
labels_t = labels.clone().detach().to(torch.float)
edge_index = adj_t.nonzero().t().contiguous().clone().detach().to(torch.long)

# Split the data into training and testing sets
train_mask = torch.zeros(len(labels_t), dtype=torch.bool)
train_mask[:230] = True
test_mask = torch.zeros(len(labels_t), dtype=torch.bool)
test_mask[230:] = True

patient_indices_train=list(range(1,231))
patient_indices_test=list(range(231,256))

# Initialize model and optimizer
model = GCN()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Define the loss function
criterion = torch.nn.BCEWithLogitsLoss()

# Train the model
for epoch in range(30):
    model.train()
    optimizer.zero_grad()
    out = model(features_t, edge_index)
    patient_nodes = torch.tensor(patient_indices_train, dtype=torch.long)
    train_loss = criterion(out[patient_nodes], labels_t[train_mask])
    train_loss.backward()
    optimizer.step()

# Evaluate on the test set
model.eval()
out = model(features_t, edge_index)
patient_nodes = torch.tensor(patient_indices_test, dtype=torch.long)
test_loss = criterion(out[patient_nodes], labels_t[test_mask])
pred = (out[patient_nodes]> 0.5).float()
correct = (pred==labels_t[test_mask]).sum().item()
acc = correct / test_mask.sum().item()
print("Test accuracy: {:.2f}%".format(acc * 100))

import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

# Define the network architecture
class Net(torch.nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = GCNConv(1077, 16)
        self.conv2 = GCNConv(16, 2)

    def forward(self, x, edge_index):
        x = F.relu(self.conv1(x, edge_index))
        x = F.dropout(x, training=self.training)
        x = self.conv2(x, edge_index)
        return x

# Convert data to PyTorch format
features_t = torch.tensor(feature_matrix, dtype=torch.float)
adj_t = torch.tensor(adj_matrix, dtype=torch.float)
labels_t = labels.clone().detach().to(torch.float)
edge_index = adj_t.nonzero().t().contiguous().clone().detach().to(torch.long)

# Split the data into training and testing sets
train_mask = torch.zeros(len(labels_t), dtype=torch.bool)
train_mask[:200] = True
test_mask = torch.zeros(len(labels_t), dtype=torch.bool)
test_mask[200:] = True

# Initialize model and optimizer
model = Net()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Set up the loss function
criterion = torch.nn.BCEWithLogitsLoss()

patient_indices_train=list(range(1,201))
patient_indices_test=list(range(201,256))

# Set up the training loop
model.train()
for epoch in range(30):
    optimizer.zero_grad()
    out = model(features_t, edge_index)
    patient_nodes = torch.tensor(patient_indices_train, dtype=torch.long)
    out = out[patient_nodes] # PyTorch indexing
    #out = out[train_mask] # PyTorch indexing
    loss = criterion(out, labels_t[train_mask])
    loss.backward()
    optimizer.step()


# Evaluate the model on the test set
model.eval()
with torch.no_grad():
    out = model(features_t, edge_index)
    patient_nodes = torch.tensor(patient_indices_test, dtype=torch.long)
    out = out[patient_nodes] # PyTorch indexing
    # pred = (torch.sigmoid(out) > 0.5).float()
    pred = (out > 0.5).float()
    correct = pred.eq(labels_t[test_mask]).sum().item()
    acc = correct / test_mask.sum().item()
    print("Test accuracy: {:.2f}%".format(acc * 100))

"""# ***GAT***"""

# Define the GAT model
class GAT(torch.nn.Module):
    def __init__(self):
        super(GAT, self).__init__()
        self.conv1 = GATConv(1077, 16)
        self.conv2 = GATConv(16, 16)
        self.mlp = torch.nn.Linear(16, 2)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = self.conv2(x, edge_index)
        x = x.relu()
        x = self.mlp(x)
        return x

# Convert data to PyTorch format
features_t = torch.tensor(feature_matrix, dtype=torch.float)
adj_t = torch.tensor(adj_matrix, dtype=torch.float)
labels_t = labels.clone().detach().to(torch.float)
edge_index = adj_t.nonzero().t().contiguous().clone().detach().to(torch.long)

# Split the data into training and testing sets
train_mask = torch.zeros(len(labels_t), dtype=torch.bool)
train_mask[:200] = True
test_mask = torch.zeros(len(labels_t), dtype=torch.bool)
test_mask[200:] = True

patient_indices_train=list(range(1,201))
patient_indices_test=list(range(201,256))

# Initialize model and optimizer
model = GAT()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Define the loss function
criterion = torch.nn.BCEWithLogitsLoss()

# Train the model
for epoch in range(30):
    model.train()
    optimizer.zero_grad()
    out = model(features_t, edge_index)
    patient_nodes = torch.tensor(patient_indices_train, dtype=torch.long)
    train_loss = criterion(out[patient_nodes], labels_t[train_mask])
    train_loss.backward()
    optimizer.step()

# Evaluate on the test set
model.eval()
out = model(features_t, edge_index)
patient_nodes = torch.tensor(patient_indices_test, dtype=torch.long)
test_loss = criterion(out[patient_nodes], labels_t[test_mask])
pred = (out[patient_nodes]> 0.5).float()
correct = (pred==labels_t[test_mask]).sum().item()
acc = correct / test_mask.sum().item()
print("Test accuracy: {:.2f}%".format(acc * 100))

"""# ***GRAPHSAGE***"""

# Define the GRAPHSAGE model
class SAGE(torch.nn.Module):
    def __init__(self):
        super(SAGE, self).__init__()
        self.conv1 = SAGEConv(1077, 16)
        self.conv2 = SAGEConv(16, 16)
        self.mlp = torch.nn.Linear(16, 2)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = self.conv2(x, edge_index)
        x = x.relu()
        x = self.mlp(x)
        return x

# Convert data to PyTorch format
features_t = torch.tensor(feature_matrix, dtype=torch.float)
adj_t = torch.tensor(adj_matrix, dtype=torch.float)
labels_t = labels.clone().detach().to(torch.float)
edge_index = adj_t.nonzero().t().contiguous().clone().detach().to(torch.long)

# Split the data into training and testing sets
train_mask = torch.zeros(len(labels_t), dtype=torch.bool)
train_mask[:200] = True
test_mask = torch.zeros(len(labels_t), dtype=torch.bool)
test_mask[200:] = True

patient_indices_train=list(range(1,201))
patient_indices_test=list(range(201,256))

# Initialize model and optimizer
model = SAGE()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Define the loss function
criterion = torch.nn.BCEWithLogitsLoss()

# Train the model
for epoch in range(30):
    model.train()
    optimizer.zero_grad()
    out = model(features_t, edge_index)
    patient_nodes = torch.tensor(patient_indices_train, dtype=torch.long)
    train_loss = criterion(out[patient_nodes], labels_t[train_mask])
    train_loss.backward()
    optimizer.step()

# Evaluate on the test set
model.eval()
out = model(features_t, edge_index)
patient_nodes = torch.tensor(patient_indices_test, dtype=torch.long)
test_loss = criterion(out[patient_nodes], labels_t[test_mask])
pred = (out[patient_nodes]> 0.5).float()
correct = (pred==labels_t[test_mask]).sum().item()
acc = correct / test_mask.sum().item()
print("Test accuracy: {:.2f}%".format(acc * 100))